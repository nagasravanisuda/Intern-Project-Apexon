# Mortality Prediction using MIMIC-III Dataset with MLOps

This project focuses on predicting patient mortality using the MIMIC-III dataset by implementing a complete MLOps pipeline. It includes robust training and inference pipelines, use of synthetic data generation, feature engineering, and model deployment practices. The project uses CI/CD workflows to ensure streamlined and reproducible model lifecycle management.

---

## ğŸš€ Project Overview

The goal of this project is to build a machine learning model to predict mortality in ICU patients using the MIMIC-III dataset. The project is designed with MLOps best practices in mind and includes:

- ğŸ”§ Training pipeline  
- ğŸ” Inference pipeline  
- ğŸ” Reusable code (Class-based implementation)  
- âœ… CI/CD workflows using GitHub Actions  

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ training_pipeline/
â”‚ â””â”€â”€ train.py
â”œâ”€â”€ inference_pipeline/
â”‚ â””â”€â”€ inference.py
â”œâ”€â”€ cicd/
â”‚ â”œâ”€â”€ training.yml
â”‚ â””â”€â”€ inference.yml
â”œâ”€â”€ artifacts/
â”‚ â”œâ”€â”€ model.pkl
â”‚ â”œâ”€â”€ scaler.pkl
â”‚ â””â”€â”€ selected_features.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ—ï¸ Training Pipeline

The training pipeline includes:

- ğŸ“¥ Data Ingestion from Azure Blob Storage (26 files, selected relevant ones)  
- ğŸ§“ Age Column Creation from existing features  
- ğŸ§¹ Preprocessing (cleaning, encoding)  
- ğŸ§¬ Synthetic Data Generation using SDV's TVAE (deep learning-based tabular synthesis)  
- ğŸ¯ Feature Selection using statistical and model-based techniques  
- ğŸ¤– Model Training and artifact saving:  
  - Trained model (`model.pkl`)  
  - Scaler (`scaler.pkl`)  
  - Selected features (`selected_features.pkl`)  

These artifacts are saved for reuse during inferenceâ€”no retraining is required unless explicitly needed.

---

## ğŸ” Inference Pipeline

The inference pipeline includes:

- ğŸ§© Input data handling and preprocessing similar to training  
- ğŸ” Reuse of trained model, scaler, and selected features  
- ğŸ“Š Prediction on unseen data  
- ğŸ§± Packaged as a reusable Python class for easy integration into other systems  

---

## âš™ï¸ CI/CD Workflows

CI/CD is implemented using GitHub Actions:

- `training.yml`: Automates training pipeline (optional retraining)  
- `inference.yml`: Validates and tests inference pipeline  
- `requirements.txt`: Includes all project dependencies for automated builds  

---

## ğŸ“¦ Dependencies

Install all dependencies with:

```bash
pip install -r requirements.txt
```
## ğŸ“ˆ Results

The trained model is capable of generalizing well to unseen data, thanks to:

- Strong preprocessing pipeline  
- Synthetic data augmentation using TVAE  
- Proper feature selection and scaling  
- Artifact reuse in production  

---

## ğŸ§  Dataset

The model is trained using a subset of the MIMIC-III clinical dataset.  
*(Ensure you have proper credentials to access this dataset.)*

---

## ğŸ§° Technologies Used

- Python  
- scikit-learn, pandas, numpy  
- SDV (TVAE) for synthetic data generation  
- Azure Blob Storage  
- GitHub Actions for CI/CD  
- Pickle for artifact serialization  
